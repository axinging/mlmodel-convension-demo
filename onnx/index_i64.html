<!DOCTYPE html>
<html>
<header>
    <title>ONNX Runtime JavaScript examples: Quick Start - Web (using bundler)</title>
</header>

<body>
    <canvas id="input-canvas" , width=224, height=224></canvas>
    <script src="./web_squeeze/dist/ort.all.js"></script>
    <script src="./imagenet_classes.js"></script>
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
    <script>

        function runPyScript(input) {
            var jqXHR = $.ajax({
                type: "POST",
                url: "http://127.0.0.1:5000/login",
                async: false,
                data: { name: input }
            });

            return jqXHR.responseText;
        }
        let feedsInfo = [];
        let session;
        let warmupTimes = 1;
        let runTimes = 0;
        //ort.env.logLevel = 'verbose';
        //ort.env.debug = true;
        async function run(modelName, ep = 'webgpu', enableGraphCapture = false) {
            let batch_size = 1;
            let sequence_length = 128;
            const buffer = new ArrayBuffer(8 * sequence_length);
            const bigint64 = new BigInt64Array(buffer);
            for (let i = 0; i < batch_size * sequence_length; i++) {
                bigint64[i] = BigInt(i);
            }
            const tensor = new ort.Tensor("int64", bigint64, [batch_size, sequence_length]);

            // set option
            const option = {
                executionProviders: [
                    {
                        name: ep,
                    },
                ],
                graphOptimizationLevel: 'disabled',
                optimizedModelFilePath1: 'opt.onnx'
            };

            option.enableGraphCapture = enableGraphCapture;
            const modelPath = './models/' + modelName + '.onnx';

            // const res = runPyScript(modelPath);
            session = await ort.InferenceSession.create(modelPath, option);

            let feedsTensor = null;
            if (enableGraphCapture) {
                let webgpuInputBuffer;
                let webgpuDevice = ort.env.webgpu.device;
                let data = bigint64;
                let bufferSize = 8 * sequence_length;
                let dims = [batch_size, sequence_length];
                let type = "int64";
                webgpuInputBuffer = webgpuDevice.createBuffer({
                    size: bufferSize,
                    usage: GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST | GPUBufferUsage.STORAGE,
                });

                webgpuDevice.queue.writeBuffer(webgpuInputBuffer, 0, data);
                feedsTensor = ort.Tensor.fromGpuBuffer(webgpuInputBuffer, { dataType: type, dims });
            }
            let feeds = { attention_mask: enableGraphCapture ? feedsTensor : tensor };
            const start = performance.now();
            const result = await session.run(feeds);
            const time = performance.now() - start;
            console.log(time);
            if (enableGraphCapture) {
                return await result['/albert/Sub_output_0'].getData();
            } else {
                return result['/albert/Sub_output_0'].cpuData;
            }
        }
        function arraysEqual(a1, a2) {
            return JSON.stringify(a1) == JSON.stringify(a2);
        }
        async function main() {
            let modelName = 'modified_albert-base-v2_1';
            const res2 = await run(modelName, 'wasm');
            const res1 = await run(modelName, 'webgpu');

            // modelName = 'modified_modified_modified_whisper-tiny-decoder-edit';
            //const res2 = await run(modelName, true);
            //console.log(arraysEqual(res1, res2));
        }
        main();
    </script>
</body>

</html>
